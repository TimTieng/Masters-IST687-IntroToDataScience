# Intro to Data Science - HW 3
##### Copyright Jeffrey Stanton, Jeffrey Saltz, and Jasmina Tachev
```{r}
# Enter your name here: Tim Tieng
```

### Attribution statement: (choose only one and delete the rest)


```{r}
# 3. I did this homework with help from <Matthew Belizaire> but did not cut and paste any code.
```

### Reminders of things to practice from last week: 
Make a data frame		data.frame( ) <br>
Row index of max/min	which.max( )  which.min( )<br>
Sort value or order rows	sort( )   order( )<br>
Descriptive statistics 	mean( ) sum( ) max( ) <br>
Conditional statement	if (condition) “true stuff” else “false stuff”<br>

### This Week: 
Often, when you get a dataset, it is not in the format you want. You can (and should) use code to refine the dataset to become more useful. As Chapter 6 of Introduction to Data Science mentions, this is called “data munging.” In this homework, you will read in a dataset from the web and work on it (in a data frame) to improve its usefulness.


## Part 1: Use read_csv( ) to read a CSV file from the web into a data frame:

A.	Use R code to read directly from a URL on the web. Store the dataset into a new dataframe, called dfComps. <br>
The URL is:    <br>
"https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv" <br>
**Hint:** use read_csv( ), not read.csv( ). This is from the **tidyverse package**. Check the help to compare them.



```{r}
#  Import tidyverse
library(tidyverse)

# Create df using read_csv()
dfComps <- data.frame(read_csv("https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv"))
```

## Part 2: Create a new data frame that only contains companies with a homepage URL:

E.	Use **subsetting** to create a new dataframe that contains only the companies with homepage URLs (store that dataframe in **urlComps**).


```{r}
# Create the Df, 
urlComps <- dfComps[which(dfComps$homepage_url != 'NA'),]
# Confirm if filtering worked; should be less than rows returned above
str(urlComps) # Returns 44435 Rows
head(urlComps$homepage_url)

```

D.	How many companies are missing a homepage URL?


```{r}
# Sum up how many values in the Homepage column contains "NA"
numNullURL <- sum(is.na(dfComps$homepage_url))
numNullURL
```

## Part 3: Analyze the numeric variables in the dataframe.

G.	How many **numeric variables** does the dataframe have? You can figure that out by looking at the output of **str(urlComps)**. 

H.	What is the average number of funding rounds for the companies in **urlComps**?


```{r}
# Check how many numerical data types in urlComps
str(urlComps)
# funding_rounds, founded_year are numerical datatypes (2x Columns)

# Find the mean of funding rounds columns in urlComps df Approach 1
avgFundingRounds <- mean(urlComps$funding_rounds)
avgFundingRounds

# Mean - Approach 2
summaryFundingRounds <- summary(urlComps$funding_rounds)
summaryFundingRounds # Values match
```

I.	What year was the oldest company in the dataframe founded? <br>
**Hint:** If you get a value of “NA,” most likely there are missing values in this variable which preclude R from properly calculating the min & max values. You can ignore NAs with basic math calculations. For example, instead of running mean(urlComps$founded_year), something like this will work for determining the average (note that this question needs to use a different function than 'mean'. 


```{r}
#mean(urlComps$founded_year, na.rm=TRUE)

#your code goes here - Note that oldest company should be using Min()
oldestCompany <- min(urlComps$founded_year, na.rm = TRUE)
oldestCompany
```

## Part 4:  Use string operations to clean the data.

K.	The **permalink variable** in **urlComps** contains the name of each company but the names are currently preceded by the prefix “/organization/”. We can use str_replace() in tidyverse or gsub() to clean the values of this variable:


```{r}
# Clean up a specific column using str_replace(<df+Column>,<value to replace> , <replacing value>)
urlComps$permalink <- str_replace(urlComps$permalink, "/organization/", " ")
head(urlComps$permalink)
```

L.	Can you identify another variable which should be numeric but is currently coded as character? Use the as.numeric() function to add a new variable to **urlComps** which contains the values from the char variable as numbers. Do you notice anything about the number of NA values in this new column compared to the original “char” one?  


```{r}
# Look at urlComps column datatypes
str(urlComps) # Funding_total_usd is a string

# Cast datatype as numeric using as.numeric()
urlComps$funding_new <- as.numeric(urlComps$funding_total_usd)
str(urlComps)
```

M.	To ensure the char values are converted correctly, we first need to remove the spaces between the digits in the variable. Check if this works, and explain what it is doing:


```{r}
library(stringi)
urlComps$funding_new <- stri_replace_all_charclass(urlComps$funding_total_usd,"\\p{WHITE_SPACE}", "")

# To my understanding, the stri_replace_all_charclass() function is a replacement function on a specific class. In this class, it will replace the value of "\\p{WHITE_SPACE}" found in the column of funding_total_usd with an empty string. This is primarily a data cleaning function to ensure all values in a given field are the same. 
```

N. You are now ready to convert **urlComps$funding_new** to numeric using as.numeric(). 

Calculate the average funding amount for **urlComps**. If you get “NA,” try using the **na.rm=TRUE** argument from problem I.


```{r}
# Should be able to convert now; automatically use na.rm =TRUE 
urlComps$funding_new <- as.numeric(urlComps$funding_new)
fundingNewAvg <- mean(urlComps$funding_new, na.rm = TRUE)
fundingNewAvg
```

Sample three unique observations from urlComps$funding_rounds, store the results in the vector 'observations'


```{r}
# Create a vector; sample(<columnToSample> , <numOfSamples>, True=To create a new vector)
observations <- sample(urlComps$funding_rounds, 3, replace = TRUE)
observations
```

Take the mean of those observations


```{r}
# calculate mean of samples
s1Mean <- mean(observations)
s1Mean
```

Do the two steps (sampling and taking the mean) in one line of code


```{r}
s1meanApproach2 <- mean(sample(urlComps$funding_rounds, 3, replace = TRUE))
s1meanApproach2
```

Explain why the two means are (or might be) different

Use the replicate( ) function to repeat your sampling of three observations of urlComps$funding_rounds  observations five times. The first argument to replicate( ) is the number of repeats you want. The second argument is the little chunk of code you want repeated.


```{r}
replicateAns <- replicate(5, sample(urlComps$funding_rounds,3, replace = TRUE))
replicateAns

```

Rerun your replication, this time doing 20 replications and storing the output of replicate() in a variable called **values**.


```{r}
values <- replicate(20, mean(sample(urlComps$funding_rounds,3, replace = TRUE)))
values
```

Generate a **histogram** of the means stored in **values**. 


```{r}
hist(values)
```

Rerun your replication, this time doing 1000 replications and storing the output of replicate() in a variable called **values**, and then generate a histogram of **values**.


```{r}
values <- replicate(1000, mean(sample(urlComps$funding_rounds,3, replace = TRUE)))
hist(values)
```

Repeat the replicated sampling, but this time, raise your sample size from 3 to 22. How does that affect your histogram? Explain in a comment.


```{r}
values <- replicate(1000, mean(sample(urlComps$funding_rounds,22, replace = TRUE)))
hist(values)
```

Explain in a comment below, the last three histograms, why do they look different?


```{r}
# The three histograms depict different outcomes if you manipulate a given parameter. The difference between the first histogram(baseline graph) and second histogram is that we changed the replication amount to 1000 times. This essentially changed the frequency in which a mean value is derived. lastly, the third graph explains the rule of thumb that as your sample size approaches infinity, the distribution shape turns more like a normal distribution.
```
